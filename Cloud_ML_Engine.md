

# Cloud ML Engine (GSP076)



This labs gives you a hands-on practice, end-to-end experience of training and prediction on Tensorflow on Google Cloud Machine Learning Engine.



## Quick Note

*   Dataset: <https://archive.ics.uci.edu/ml/datasets/Census+Income>
    *   We first use deep neural nets (DNNs) to learn high-level abstractions about complex features or interactions between features in the dataset. Theses model further combine the outputs from the DNN with a linear regression performed on this simpler features. This is effective on many structured data problems.
*   Objective
    *   Create a TensorFlow training application and validate it locally.
    *   Run your training job on a single worker instance in the cloud.
    *   Run your training job as a distributed training job in the cloud.
    *   Optimize your hyperparameters by using hyperparameter tuning.
    *   Deploy a model to support prediction.
    *   Request an online prediction and see the response.
    *   Request a batch prediction.



## Google Cloud Shell



## Install Tensorflow

```sh
pip install --user --upgrade tensorflow
```

Validate that the tensorflow install was successful.

```sh
python -c "import tensorflow as tf; print('Tensorlfow version: {}'.format(tf.VERSION));"
```



## Clone the example repo

```sh
git clone https://github.com/GoogleCloudPlatform/cloudml-samples.git
```

Here we want to use `estimator` API.

```sh
cd cloudml-samples/census/estimator
```



## Develop and validate your training application locally

### Get your training data

```sh
mkdir data
gsutil -m cp gs://cloud-samples-data/ml-engine/census/data/* data/
```

Set the TRAIN_DATA path and EVAL_DATA path.

```sh
export TRAIN_DATA=$(pwd)/data/adult.data.csv
export EVAL_DATA=$(pwd)/data/adult.test.csv
```

You can view the partial data.

```sh
head data/adult.data.csv
```



## Install dependencies

Install the necessary and dependent packages.

```sh
pip install --user -r ../requirements.txt
```



## Run a local training job

Specify an output directory and set a `MODEL_DIR` variable.

```sh
export MODEL_DIR=output
```

Run the training job locally.

```sh
gcloud ai-platform local train \
    --module-name trainer.task \
    --package-path trainer/ \
    --job-dir $MODEL_DIR \
    --train-files $TRAIN_DATA \
    --eval-files $EVAL_DATA \
    --train-steps 1000 \
    --eval-steps 100 \
    --verbosity DEBUG
```

### Inspect the summary logs using Tensorboard

We can use a visualization tool, named `TensorBoard`, to monitor the training logs.

```sh
tensorboard --logdir=$MODEL_DIR --port=8080
```

Click the **Web Preview** icon, then click **Preview on port 8080** to surf the Tensorboard on the new tab.

Type `CTRL+C` in the cloud shell to shut down TensorBoard.



### Running model prediction locally (in Cloud Shell)

The directory `/output/export/census` holds the model exported as a result of running training locally.

```sh
ls output/export/census/
```

You should see a directory whose name is all constisted of digits, it is a timestamp.

```sh
1559272937
```

Copy this timestamp and run the following command to start a prediction.

```sh
gcloud ai-platform local predict \
--model-dir output/export/census/1559272937 \
--json-instances ../test.json
```

Where class 0 means income <= 50K and the other class 1 means income > 50K.



## Use your trained model for prediction

We use `test.json` data in the github repository was cloned before.



## Run your training job in the cloud

### Set up a Google Cloud Storage bucket

```sh
PROJECT_ID=$(gcloud config list project --format "value(core.project)")
BUCKET_NAME=${PROJECT_ID}-mlengine
echo $BUCKET_NAME
REGION=us-central1
```

Create the new bucket.

```sh
gsutil mb -l $REGION gs://$BUCKET_NAME
gsutil ls  # to check the bucket was successfully created
```

Upload the data files to the bucket.

```sh
gsutil cp -r data gs://$BUCKET_NAME/data
```

Set the `TRAIN_DATA` and `EVAL_DATA` variables.

```sh
TRAIN_DATA=gs://$BUCKET_NAME/data/adult.data.csv
EVAL_DATA=gs://$BUCKET_NAME/data/adult.test.csv
```

Copy the json test file `test.json` to cloud storage bucket.

```sh
gsutil cp ../test.json gs://$BUCKET_NAME/data/test.json
```

Set the `TEST_JSON` variable.

```sh
TEST_JSON=gs://$BUCKET_NAME/data/test.json
```



## Run a single-instance trainer in the cloud

Assign a training name.

```sh
JOB_NAME=census_single_1
```

Specify a directory for output generated by Cloud ML Engine by setting an `OUTPUT_PATH` variable.

```sh
OUTPUT_PATH=gs://$BUCKET_NAME/$JOB_NAME
```

Running the command to submit a training job in the cloud that uses a single process. Set `--verbosity` to `DEBUG` in order to inspect full logging output and other metrics.

```sh
gcloud ai-platform jobs submit training $JOB_NAME \
    --job-dir $OUTPUT_PATH \
    --runtime-version 1.10 \
    --module-name trainer.task \
    --package-path trainer/ \
    --region $REGION \
    --train-files $TRAIN_DATA \
    --eval-files $EVAL_DATA \
    --train-steps 1000 \
    --eval-steps 100 \
    --verbosity DEBUG
```

After a successful submit, you can now monitor the process of the training job.

```sh
gcloud ai-platform jobs stream-logs $JOB_NAME
```

Also you can run the command to list the output.

```sh
gsutil ls -r $OUTPUT_PATH
```

Use TensorBoard to monitor the result

```sh
tensorboard --logdir=$OUTPUT_PATH --port=8080
```



## Deploy your model to support prediction

By deploying a model to Cloud ML Engine to serve online prediction requests, you get the benefit of scalable serving.

Create a Cloud ML Engine model.

```sh
MODEL_NAME=census
gcloud ai-platform models create $MODEL_NAME --regions=$REGION
```

Select the exported model to use.

```sh
gsutil ls -r $OUTPUT_PATH/export
```

And select the one with path `$OUTPUT_PATH/export/census/<timestamp>/` and export the value as a variable.

```sh
MODEL_BINARIES=$OUTPUT_PATH/export/census/1559274982/
```

You now can deploy the trained model. Here `v1` is the model version of your machine learning solution and this version is also one of necessary parameters while sending a predict request to the cloud ML engine.

```sh
gcloud ai-platform versions create v1 \
--model $MODEL_NAME \
--origin $MODEL_BINARIES \
--runtime-version 1.10
```

You can see a list of your models using `model list` command.

```sh
gcloud ai-platform models list
```

### Send an online prediction request to your deployed model

```sh
gcloud ai-platform predict \
--model $MODEL_NAME \
--version v1 \
--json-instances ../test.json
```





